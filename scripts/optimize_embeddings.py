#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì„±ê²½ ì„ë² ë”© íŒŒì¼ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
514MB â†’ 25MB ì´í•˜ë¡œ ì••ì¶•
"""

import json
import gzip
import numpy as np
import os
from typing import List, Dict, Any

def optimize_bible_embeddings():
    """ì„±ê²½ ì„ë² ë”© íŒŒì¼ì„ Railway ë°°í¬ìš©ìœ¼ë¡œ ìµœì í™”"""
    
    input_file = r"C:\Users\user\Desktop\ai-bible-assistant\bible_embeddings.json"
    
    print("ğŸ”„ ì„±ê²½ ì„ë² ë”© íŒŒì¼ ìµœì í™” ì‹œì‘...")
    print(f"ğŸ“ ì›ë³¸ íŒŒì¼ í¬ê¸°: {os.path.getsize(input_file) / (1024*1024):.2f} MB")
    
    # 1ë‹¨ê³„: ì›ë³¸ íŒŒì¼ ë¡œë“œ (JSONL í˜•íƒœ ì§€ì›)
    print("\nğŸ“– ì›ë³¸ íŒŒì¼ ë¡œë”©...")
    data = []
    
    try:
        # ë¨¼ì € ì¼ë°˜ JSON ì‹œë„
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print("âœ… JSON ë°°ì—´ í˜•íƒœë¡œ ë¡œë”© ì„±ê³µ")
    except json.JSONDecodeError:
        # JSONL í˜•íƒœë¡œ ë‹¤ì‹œ ì‹œë„
        print("ğŸ”„ JSONL í˜•íƒœë¡œ ì¬ì‹œë„...")
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f):
                if line.strip():  # ë¹ˆ ì¤„ ë¬´ì‹œ
                    try:
                        item = json.loads(line.strip())
                        data.append(item)
                        
                        # ì§„í–‰ë¥  í‘œì‹œ (1000ì¤„ë§ˆë‹¤)
                        if line_num % 1000 == 0:
                            print(f"ë¡œë”© ì¤‘... {line_num + 1} ì¤„")
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ {line_num + 1}ë²ˆì§¸ ì¤„ íŒŒì‹± ì˜¤ë¥˜: {e}")
                        continue
        print("âœ… JSONL í˜•íƒœë¡œ ë¡œë”© ì„±ê³µ")
    
    print(f"ğŸ“Š ì´ êµ¬ì ˆ ìˆ˜: {len(data)}")
    print(f"ğŸ“Š ì„ë² ë”© ì°¨ì›: {len(data[0]['embedding']) if data else 'N/A'}")
    
    # 2ë‹¨ê³„: ì„ë² ë”© ë²¡í„° ì •ë°€ë„ ê°ì†Œ (float64 â†’ float16)
    print("\nğŸ”§ ì„ë² ë”© ë²¡í„° ì •ë°€ë„ ìµœì í™”...")
    optimized_data = []
    
    for i, item in enumerate(data):
        # ì§„í–‰ë¥  í‘œì‹œ
        if i % 1000 == 0:
            print(f"ì§„í–‰ë¥ : {i}/{len(data)} ({i/len(data)*100:.1f}%)")
        
        # ì„ë² ë”© ë²¡í„°ë¥¼ float16ìœ¼ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ 50% ì ˆì•½)
        embedding_array = np.array(item['embedding'], dtype=np.float16)
        
        optimized_item = {
            'id': item['id'],
            'embedding': embedding_array.tolist(),
            'text': item['text'],
            'book': item['book'],
            'chapter': item['chapter'],
            'verse': item['verse']
        }
        optimized_data.append(optimized_item)
    
    # 3ë‹¨ê³„: JSON ì••ì¶• ì €ì¥
    print("\nğŸ’¾ ì••ì¶• íŒŒì¼ ì €ì¥...")
    compressed_file = "bible_embeddings_optimized.json.gz"
    
    with gzip.open(compressed_file, 'wt', encoding='utf-8') as f:
        json.dump(optimized_data, f, separators=(',', ':'), ensure_ascii=False)
    
    # 4ë‹¨ê³„: ê²°ê³¼ í™•ì¸
    compressed_size = os.path.getsize(compressed_file)
    compression_ratio = (1 - compressed_size / os.path.getsize(input_file)) * 100
    
    print(f"\nâœ… ìµœì í™” ì™„ë£Œ!")
    print(f"ğŸ“ ì••ì¶• íŒŒì¼ í¬ê¸°: {compressed_size / (1024*1024):.2f} MB")
    print(f"ğŸ“‰ ì••ì¶•ë¥ : {compression_ratio:.1f}%")
    
    # 5ë‹¨ê³„: Railway í˜¸í™˜ì„± ì²´í¬
    if compressed_size < 25 * 1024 * 1024:  # 25MB
        print("âœ… Railway ë°°í¬ ì í•© (25MB ì´í•˜)")
    else:
        print("âš ï¸  ì¶”ê°€ ìµœì í™” í•„ìš” (25MB ì´ˆê³¼)")
        
        # ì¶”ê°€ ìµœì í™”: íŒŒì¼ ë¶„í• 
        print("\nğŸ”„ íŒŒì¼ ë¶„í•  ì§„í–‰...")
        split_large_file(optimized_data)
    
    return compressed_file

def split_large_file(data: List[Dict[str, Any]]):
    """í° íŒŒì¼ì„ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• """
    
    chunk_size = len(data) // 4  # 4ê°œ íŒŒì¼ë¡œ ë¶„í• 
    
    for i in range(4):
        start_idx = i * chunk_size
        end_idx = start_idx + chunk_size if i < 3 else len(data)
        
        chunk_data = data[start_idx:end_idx]
        chunk_file = f"bible_embeddings_part_{i+1}.json.gz"
        
        with gzip.open(chunk_file, 'wt', encoding='utf-8') as f:
            json.dump(chunk_data, f, separators=(',', ':'), ensure_ascii=False)
        
        chunk_size_mb = os.path.getsize(chunk_file) / (1024*1024)
        print(f"ğŸ“¦ Part {i+1}: {chunk_size_mb:.2f} MB ({len(chunk_data)} êµ¬ì ˆ)")

def create_index_file(data: List[Dict[str, Any]]):
    """ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„±"""
    
    index_data = []
    for item in data:
        index_item = {
            'id': item['id'],
            'text': item['text'],
            'book': item['book'],
            'chapter': item['chapter'],
            'verse': item['verse']
        }
        index_data.append(index_item)
    
    with gzip.open('bible_index.json.gz', 'wt', encoding='utf-8') as f:
        json.dump(index_data, f, separators=(',', ':'), ensure_ascii=False)
    
    index_size = os.path.getsize('bible_index.json.gz') / (1024*1024)
    print(f"ğŸ“š ì¸ë±ìŠ¤ íŒŒì¼: {index_size:.2f} MB")

def test_optimized_file():
    """ìµœì í™”ëœ íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    
    print("\nğŸ§ª ìµœì í™” íŒŒì¼ í…ŒìŠ¤íŠ¸...")
    
    try:
        with gzip.open('bible_embeddings_optimized.json.gz', 'rt', encoding='utf-8') as f:
            test_data = json.load(f)
        
        print(f"âœ… ë¡œë”© ì„±ê³µ: {len(test_data)} êµ¬ì ˆ")
        print(f"ğŸ“Š ì²« ë²ˆì§¸ êµ¬ì ˆ: {test_data[0]['text']}")
        print(f"ğŸ“Š ì„ë² ë”© ì°¨ì›: {len(test_data[0]['embedding'])}")
        
        # ì„ë² ë”© ë²¡í„° ë³µì› í…ŒìŠ¤íŠ¸
        embedding = np.array(test_data[0]['embedding'], dtype=np.float32)
        print(f"ğŸ“Š ì„ë² ë”© ë²”ìœ„: {embedding.min():.3f} ~ {embedding.max():.3f}")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    # ë©”ì¸ ìµœì í™” ì‹¤í–‰
    optimized_file = optimize_bible_embeddings()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_optimized_file()
    
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("1. ìƒì„±ëœ .gz íŒŒì¼ì„ GitHub Releasesì— ì—…ë¡œë“œ")
    print("2. ë‹¤ìš´ë¡œë“œ URLì„ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •")
    print("3. Railway ë°°í¬ ì§„í–‰")
    
    print(f"\nğŸ“‹ ìƒì„±ëœ íŒŒì¼ë“¤:")
    for file in ['bible_embeddings_optimized.json.gz', 'bible_index.json.gz']:
        if os.path.exists(file):
            size = os.path.getsize(file) / (1024*1024)
            print(f"  - {file}: {size:.2f} MB")